{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='gray'>Thiago</font>\n",
    "# <font color='gray'>Big Data Real-Time Analytics com Python e Spark</font>\n",
    "\n",
    "\n",
    "## <font color='gray'>Machine Learning com PySpark</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.9.13\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "#!pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "#!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa o findspark e inicializa\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Thiago Gragnanello\n",
      "\n",
      "findspark: 2.0.1\n",
      "numpy    : 1.21.5\n",
      "pyspark  : 3.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Thiago Gragnanello\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/15 20:54:51 WARN Utils: Your hostname, thiago-Nitro resolves to a loopback address: 127.0.1.1; using 192.168.0.110 instead (on interface wlp0s20f3)\n",
      "23/10/15 20:54:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/15 20:54:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Criando o Spark Context\n",
    "sc = SparkContext(appName = \"Lab5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o Spark Session\n",
    "spSession = SparkSession.builder.master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados e gerando um RDD\n",
    "dados = sc.textFile(\"dados/dataset1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dados/dataset1.csv MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colocando o RDD em cache. Esse processo otimiza a performance\n",
    "\n",
    "# Coloca os dados em uma área que o processo pode ser mais rápido\n",
    "\n",
    "\n",
    "dados.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 2) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de registros\n",
    "dados.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['consumo,numero_cilindros,capacidade,horsepower,peso,aceleracao,ano,nome',\n",
       " '30,4,79,70,2074,19.5,71,peugeot 304',\n",
       " '30,4,88,76,2065,14.5,71,fiat 124b',\n",
       " '31,4,71,65,1773,19,71,toyota corolla 1200',\n",
       " '35,4,72,69,1613,18,71,datsun 1200']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando as primeiras linhas\n",
    "\n",
    "# Variável consumo será a variável Target\n",
    "\n",
    "dados.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo a primeira linha do arquivo (cabeçalho)\n",
    "\n",
    "# Retorne o valor de x menos as linhas que tenha horsepower, por exemplo. Tira a linha do cabeçalho\n",
    "\n",
    "\n",
    "dados2 = dados.filter(lambda x: \"horsepower\" not in x)\n",
    "dados2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30,4,79,70,2074,19.5,71,peugeot 304',\n",
       " '30,4,88,76,2065,14.5,71,fiat 124b',\n",
       " '31,4,71,65,1773,19,71,toyota corolla 1200',\n",
       " '35,4,72,69,1613,18,71,datsun 1200',\n",
       " '27,4,97,60,1834,19,71,volkswagen model 111']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando as primeiras linhas\n",
    "dados2.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Limpeza dos Dados\n",
    "\n",
    "Vamos verificar se há valores ausentes. RDDs são ótimos para processamento, mas ruins para exploração, então converteremos o RDD para DataFrame Spark e então para DataFrame Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte RDD para DataFrame Spark\n",
    "\n",
    "# Não é convertido para o Pandas diretamente, pois precisa sofrer algumas alterações antes\n",
    "# Essa mudança é necessaria para manipular os dados. Em pandas é mais fácil\n",
    "\n",
    "# map = mapeia uma função por linha\n",
    "# split divide cada linha pela \",\", ou seja, separando as colunas\n",
    "# Converto para string \"str\"\n",
    "# toDF() converto para DF spark\n",
    "\n",
    "\n",
    "df_spark = dados2.map(lambda x: str(x)).map(lambda w: w.split(',')).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte DataFrame Spark para DataFrame Pandas\n",
    "df_pandas = df_spark.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_1</th>\n",
       "      <th>_2</th>\n",
       "      <th>_3</th>\n",
       "      <th>_4</th>\n",
       "      <th>_5</th>\n",
       "      <th>_6</th>\n",
       "      <th>_7</th>\n",
       "      <th>_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "      <td>70</td>\n",
       "      <td>2074</td>\n",
       "      <td>19.5</td>\n",
       "      <td>71</td>\n",
       "      <td>peugeot 304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>76</td>\n",
       "      <td>2065</td>\n",
       "      <td>14.5</td>\n",
       "      <td>71</td>\n",
       "      <td>fiat 124b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "      <td>1773</td>\n",
       "      <td>19</td>\n",
       "      <td>71</td>\n",
       "      <td>toyota corolla 1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>69</td>\n",
       "      <td>1613</td>\n",
       "      <td>18</td>\n",
       "      <td>71</td>\n",
       "      <td>datsun 1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>97</td>\n",
       "      <td>60</td>\n",
       "      <td>1834</td>\n",
       "      <td>19</td>\n",
       "      <td>71</td>\n",
       "      <td>volkswagen model 111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _1 _2  _3  _4    _5    _6  _7                    _8\n",
       "0  30  4  79  70  2074  19.5  71           peugeot 304\n",
       "1  30  4  88  76  2065  14.5  71             fiat 124b\n",
       "2  31  4  71  65  1773    19  71   toyota corolla 1200\n",
       "3  35  4  72  69  1613    18  71           datsun 1200\n",
       "4  27  4  97  60  1834    19  71  volkswagen model 111"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tem valores nulos?\n",
    "df_pandas.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não há valor nulo, mas será que há valor ausente (falta de informação)? Vamos checar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifica se há alguma linha com caracter especial \"?\"\n",
    "\n",
    "# Cada valor \"values\"\n",
    "# contém \"contains\" a string \"?\"\n",
    "# se tiver, some\n",
    "\n",
    "\n",
    "total = np.sum(df_pandas.apply(lambda x: x.str.contains('\\?')).values)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 48, 126, 330, 336, 354, 374]), array([3, 3, 3, 3, 3, 3]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vejamos quais linhas e colunas têm o caracter especial\n",
    "np.where(df_pandas.apply(lambda x: x.str.contains('\\?')).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_1                    40.9\n",
       "_2                       4\n",
       "_3                      85\n",
       "_4                       ?\n",
       "_5                    1835\n",
       "_6                    17.3\n",
       "_7                      80\n",
       "_8    renault lecar deluxe\n",
       "Name: 330, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando uma linha\n",
    "df_pandas.iloc[330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando um valor padrão para average HP (que será usado para preencher os valores ausentes)\n",
    "mediaHP = sc.broadcast(75.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para limpeza dos dados\n",
    "def limpaDados(inputStr) :\n",
    "    \n",
    "    # Variável global\n",
    "    global mediaHP\n",
    "    \n",
    "    # Lista de atributos\n",
    "    attList = inputStr.split(\",\")\n",
    "    \n",
    "    # Substitui o caracter ? por um valor na coluna de índice 3\n",
    "    hpValue = attList[3]\n",
    "    if hpValue == \"?\":\n",
    "        hpValue = mediaHP.value\n",
    "       \n",
    "    # Cria uma linha usando a função Row, limpando e convertendo os dados de string para float\n",
    "    linhas = Row(consumo = float(attList[0]), \n",
    "                 numero_cilindros = float(attList[1]), \n",
    "                 capacidade = float(attList[2]), \n",
    "                 hosrsepower = float(hpValue), \n",
    "                 peso = float(attList[4]), \n",
    "                 aceleracao = float(attList[5]), \n",
    "                 ano = float(attList[6]), \n",
    "                 nome = attList[7]) \n",
    "    return linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(consumo=30.0, numero_cilindros=4.0, capacidade=79.0, hosrsepower=70.0, peso=2074.0, aceleracao=19.5, ano=71.0, nome='peugeot 304'),\n",
       " Row(consumo=30.0, numero_cilindros=4.0, capacidade=88.0, hosrsepower=76.0, peso=2065.0, aceleracao=14.5, ano=71.0, nome='fiat 124b'),\n",
       " Row(consumo=31.0, numero_cilindros=4.0, capacidade=71.0, hosrsepower=65.0, peso=1773.0, aceleracao=19.0, ano=71.0, nome='toyota corolla 1200'),\n",
       " Row(consumo=35.0, numero_cilindros=4.0, capacidade=72.0, hosrsepower=69.0, peso=1613.0, aceleracao=18.0, ano=71.0, nome='datsun 1200'),\n",
       " Row(consumo=27.0, numero_cilindros=4.0, capacidade=97.0, hosrsepower=60.0, peso=1834.0, aceleracao=19.0, ano=71.0, nome='volkswagen model 111')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executa a função no RDD\n",
    "dados3 = dados2.map(limpaDados)\n",
    "dados3.cache()\n",
    "dados3.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Exploratória de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um Dataframe\n",
    "df_carros = spSession.createDataFrame(dados3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+\n",
      "|summary|          consumo| numero_cilindros|\n",
      "+-------+-----------------+-----------------+\n",
      "|  count|              398|              398|\n",
      "|   mean|23.51457286432161|5.454773869346734|\n",
      "| stddev|7.815984312565782|1.701004244533212|\n",
      "|    min|              9.0|              3.0|\n",
      "|    max|             46.6|              8.0|\n",
      "+-------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estatísticas descritivas de duas variáveis (como exemplo)\n",
    "df_carros.select(\"consumo\", \"numero_cilindros\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlação da Variável Target com: consumo 1.0\n",
      "Correlação da Variável Target com: numero_cilindros -0.7753962854205548\n",
      "Correlação da Variável Target com: capacidade -0.8042028248058978\n",
      "Correlação da Variável Target com: hosrsepower -0.774704152349872\n",
      "Correlação da Variável Target com: peso -0.8317409332443347\n",
      "Correlação da Variável Target com: aceleracao 0.4202889121016496\n",
      "Correlação da Variável Target com: ano 0.5792671330833099\n"
     ]
    }
   ],
   "source": [
    "# Encontrando a correlação entre a variável target com as variáveis preditoras (exceto o nome)\n",
    "for i in df_carros.columns:\n",
    "    if not(isinstance(df_carros.select(i).take(1)[0][0], str)) :\n",
    "        print(\"Correlação da Variável Target com:\", i, df_carros.stat.corr('consumo', i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'black'> VETOR DENSO x VETOR ESPARSO </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo para um LabeledPoint (target, Vector[features])\n",
    "# Remove colunas não relevantes ou com baixa correlação\n",
    "\n",
    "\n",
    "# Vetor Denso: Quando a maioria dos valores são diferentes de zero\n",
    "\n",
    "# Vetor Esparso: Contém muitos valores zero\n",
    "\n",
    "\n",
    "# Formato de tupla\n",
    "\n",
    "def transformaVar(row) :\n",
    "    obj = (row[\"consumo\"], Vectors.dense([row[\"peso\"], row[\"capacidade\"], row[\"numero_cilindros\"]]))\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a função no RDD e cria outro RDD\n",
    "dados4 = dados3.map(transformaVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(30.0, DenseVector([2074.0, 79.0, 4.0])),\n",
       " (30.0, DenseVector([2065.0, 88.0, 4.0])),\n",
       " (31.0, DenseVector([1773.0, 71.0, 4.0])),\n",
       " (35.0, DenseVector([1613.0, 72.0, 4.0])),\n",
       " (27.0, DenseVector([1834.0, 97.0, 4.0]))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza\n",
    "dados4.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte o RDD para DataFrame do Spark\n",
    "df_carros = spSession.createDataFrame(dados4, [\"label\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|label|          features|\n",
      "+-----+------------------+\n",
      "| 30.0| [2074.0,79.0,4.0]|\n",
      "| 30.0| [2065.0,88.0,4.0]|\n",
      "| 31.0| [1773.0,71.0,4.0]|\n",
      "| 35.0| [1613.0,72.0,4.0]|\n",
      "| 27.0| [1834.0,97.0,4.0]|\n",
      "| 26.0| [1955.0,91.0,4.0]|\n",
      "| 24.0|[2278.0,113.0,4.0]|\n",
      "| 25.0| [2126.0,97.5,4.0]|\n",
      "| 23.0| [2254.0,97.0,4.0]|\n",
      "| 20.0|[2408.0,140.0,4.0]|\n",
      "+-----+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualiza label (y) e atributos (x)\n",
    "df_carros.select(\"label\",\"features\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão em dados de Treino e de Teste com split 70/30\n",
    "(dados_treino, dados_teste) = df_carros.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_treino.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_teste.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto\n",
    "linearReg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina o objeto com dados e cria o modelo\n",
    "modelo = linearReg.fit(dados_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegressionModel: uid=LinearRegression_3ab15ef57878, numFeatures=3\n"
     ]
    }
   ],
   "source": [
    "print(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes: [-0.005892548512961131,-0.011700245587835476,-0.19225314041309582]\n",
      "Intercepto: 44.43383876145064\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo os coeficientes (o que o modelo aprendeu)\n",
    "print(\"Coeficientes: \" + str(modelo.coefficients))\n",
    "print(\"Intercepto: \" + str(modelo.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões com dados de teste\n",
    "predictions = modelo.transform(dados_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|          features|        prediction|\n",
      "+------------------+------------------+\n",
      "|[4732.0,304.0,8.0]| 11.45539941611181|\n",
      "|[4376.0,307.0,8.0]|13.518045949962467|\n",
      "|[3664.0,350.0,8.0]| 17.21042993091387|\n",
      "|[4456.0,350.0,8.0]|12.543531508648655|\n",
      "|[3169.0,302.0,8.0]| 20.68885323304573|\n",
      "|[3821.0,360.0,8.0]|16.168297358500617|\n",
      "|[4100.0,350.0,8.0]|14.641278779262816|\n",
      "|[4274.0,350.0,8.0]| 13.61597533800758|\n",
      "|[4363.0,351.0,8.0]|13.079838274766203|\n",
      "|[4464.0,400.0,8.0]|11.911378841153187|\n",
      "|[4502.0,350.0,8.0]|12.272474277052446|\n",
      "|[4735.0,440.0,8.0]| 9.846488370627306|\n",
      "|[5140.0,400.0,8.0]|  7.92801604639147|\n",
      "|[4077.0,318.0,8.0]|15.151215253871658|\n",
      "|[4385.0,400.0,8.0]|12.376890173677118|\n",
      "|[4425.0,455.0,8.0]|11.497674725827721|\n",
      "|[3777.0,318.0,8.0]|16.918979807759996|\n",
      "|[3892.0,304.0,8.0]|16.405140166999164|\n",
      "|[4135.0,318.0,8.0]| 14.80944744011991|\n",
      "|[3433.0,304.0,8.0]| 19.10981993444832|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualiza as previsões\n",
    "predictions.select(\"features\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coeficiente de determinação R2\n",
    "avaliador = RegressionEvaluator(predictionCol = \"prediction\", labelCol = \"label\", metricName = \"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7355596084362468"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resultado\n",
    "avaliador.evaluate(predictions) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
