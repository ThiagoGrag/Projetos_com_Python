{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='gray'>Thiago</font>\n",
    "# <font color='gray'>Big Data Real-Time Analytics com Python e Spark</font>\n",
    "\n",
    "\n",
    "## <font color='gray'>Machine Learning com PySpark</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Classificação Multiclasse</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos a Classificação Multiclasse com Árvores de Decisão para construir um modelo capaz de prever o resultado de uma partida de futebol com 3 resultados possíveis: vitória, derrota ou empate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.9.7\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "#!pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "#!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa o findspark e inicializa\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Thiago Gragnanello\n",
      "\n",
      "findspark: 2.0.1\n",
      "pyspark  : 3.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Thiago Gragnanello\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/15 21:29:12 WARN Utils: Your hostname, thiago-Nitro resolves to a loopback address: 127.0.1.1; using 192.168.0.110 instead (on interface wlp0s20f3)\n",
      "23/10/15 21:29:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/15 21:29:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/10/15 21:29:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Criando o Spark Context\n",
    "sc = SparkContext(appName = \"Lab5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session - usada quando se trabalha com Dataframes no Spark\n",
    "spSession = SparkSession.builder.master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados e gerando um RDD\n",
    "dados_time_futebol = sc.textFile(\"dados/dataset2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dados/dataset2.csv MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colocando o RDD em cache. Esse processo otimiza a performance.\n",
    "dados_time_futebol.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 2) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_time_futebol.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['media_faltas_sofridas,media_faltas_recebidas,media_cartoes_recebidos,media_chutes_a_gol,resultado',\n",
       " '4.8,3,1.4,0.3,vitoria',\n",
       " '5.1,3.8,1.6,0.2,vitoria',\n",
       " '4.6,3.2,1.4,0.2,vitoria',\n",
       " '5.3,3.7,1.5,0.2,vitoria']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_time_futebol.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo a primeira linha do arquivo (cabeçalho)\n",
    "dados_time_futebol_2 = dados_time_futebol.filter(lambda x: \"media_faltas_sofridas\" not in x)\n",
    "dados_time_futebol_2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza e Transformação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as colunas\n",
    "dados_time_futebol_3 = dados_time_futebol_2.map(lambda l: l.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeando as colunas\n",
    "\n",
    "## Cada linha no conjunto de dados, vou converter para um objeto tipo linha\n",
    "\n",
    "\n",
    "dados_time_futebol_4 = dados_time_futebol_3.map(lambda p: Row(media_faltas_sofridas = float(p[0]), \n",
    "                                                              media_faltas_recebidas = float(p[1]), \n",
    "                                                              media_cartoes_recebidos = float(p[2]), \n",
    "                                                              media_chutes_a_gol = float(p[3]), \n",
    "                                                              resultado = p[4] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[media_faltas_sofridas: double, media_faltas_recebidas: double, media_cartoes_recebidos: double, media_chutes_a_gol: double, resultado: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converte o RDD para DataFrame do Spark\n",
    "df_time = spSession.createDataFrame(dados_time_futebol_4)\n",
    "df_time.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(media_faltas_sofridas=4.8, media_faltas_recebidas=3.0, media_cartoes_recebidos=1.4, media_chutes_a_gol=0.3, resultado='vitoria'),\n",
       " Row(media_faltas_sofridas=5.1, media_faltas_recebidas=3.8, media_cartoes_recebidos=1.6, media_chutes_a_gol=0.2, resultado='vitoria'),\n",
       " Row(media_faltas_sofridas=4.6, media_faltas_recebidas=3.2, media_cartoes_recebidos=1.4, media_chutes_a_gol=0.2, resultado='vitoria'),\n",
       " Row(media_faltas_sofridas=5.3, media_faltas_recebidas=3.7, media_cartoes_recebidos=1.5, media_chutes_a_gol=0.2, resultado='vitoria'),\n",
       " Row(media_faltas_sofridas=5.1, media_faltas_recebidas=3.5, media_cartoes_recebidos=1.4, media_chutes_a_gol=0.2, resultado='vitoria')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um índice numérico para a coluna de label target\n",
    "stringIndexer = StringIndexer(inputCol = \"resultado\", outputCol = \"idx_resultado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 6:>                                                          (0 + 2) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Treinando o string indexer\n",
    "si_model = stringIndexer.fit(df_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o string indexer\n",
    "df_time_final = si_model.transform(df_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(resultado='derrota', idx_resultado=0.0),\n",
       " Row(resultado='vitoria', idx_resultado=2.0),\n",
       " Row(resultado='empate', idx_resultado=1.0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_final.select(\"resultado\", \"idx_resultado\").distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Exploratória de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+----------------------+-----------------------+------------------+---------+------------------+\n",
      "|summary|media_faltas_sofridas|media_faltas_recebidas|media_cartoes_recebidos|media_chutes_a_gol|resultado|     idx_resultado|\n",
      "+-------+---------------------+----------------------+-----------------------+------------------+---------+------------------+\n",
      "|  count|                  150|                   150|                    150|               150|      150|               150|\n",
      "|   mean|    5.843333333333332|    3.0573333333333337|      3.758000000000001|1.1993333333333331|     NULL|               1.0|\n",
      "| stddev|   0.8280661279778625|   0.43586628493669793|     1.7652982332594667|0.7622376689603465|     NULL|0.8192319205190404|\n",
      "|    min|                  4.3|                   2.0|                    1.0|               0.1|  derrota|               0.0|\n",
      "|    max|                  7.9|                   4.4|                    6.9|               2.5|  vitoria|               2.0|\n",
      "+-------+---------------------+----------------------+-----------------------+------------------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estatística descritiva\n",
    "df_time_final.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlação da variável idx_resultado com: media_faltas_sofridas -0.4600391565002369\n",
      "Correlação da variável idx_resultado com: media_faltas_recebidas 0.6183715308237437\n",
      "Correlação da variável idx_resultado com: media_cartoes_recebidos -0.649241830764174\n",
      "Correlação da variável idx_resultado com: media_chutes_a_gol -0.5803770334306265\n",
      "Correlação da variável idx_resultado com: idx_resultado 1.0\n"
     ]
    }
   ],
   "source": [
    "# Correlação entre as variáveis\n",
    "for i in df_time_final.columns:\n",
    "    if not(isinstance(df_time_final.select(i).take(1)[0][0], str)) :\n",
    "        print(\"Correlação da variável idx_resultado com:\", i, df_time_final.stat.corr('idx_resultado', i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Processamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um LabeledPoint (target, Vector[features])\n",
    "# Remove colunas não relevantes para o modelo ou com baixa correlação\n",
    "\n",
    "\n",
    "## Estou usando as duas variáveis (uma em texto), porque preciso para facilitar na conferência\n",
    "## O algoritmo vai olhar somente para features e label\n",
    "\n",
    "\n",
    "def transformaVar(row) :\n",
    "    obj = (row[\"resultado\"], row[\"idx_resultado\"], Vectors.dense([row[\"media_faltas_sofridas\"], \n",
    "                                                                  row[\"media_faltas_recebidas\"],\n",
    "                                                                  row[\"media_cartoes_recebidos\"], \n",
    "                                                                  row[\"media_chutes_a_gol\"]]))\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a função\n",
    "df_time_final_RDD = df_time_final.rdd.map(transformaVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vitoria', 2.0, DenseVector([4.8, 3.0, 1.4, 0.3])),\n",
       " ('vitoria', 2.0, DenseVector([5.1, 3.8, 1.6, 0.2])),\n",
       " ('vitoria', 2.0, DenseVector([4.6, 3.2, 1.4, 0.2])),\n",
       " ('vitoria', 2.0, DenseVector([5.3, 3.7, 1.5, 0.2])),\n",
       " ('vitoria', 2.0, DenseVector([5.1, 3.5, 1.4, 0.2]))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_final_RDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte o RDD para DataFrame\n",
    "df_spark = spSession.createDataFrame(df_time_final_RDD,[\"resultado\", \"label\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[resultado: string, label: double, features: vector]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----------------+\n",
      "|resultado|label|         features|\n",
      "+---------+-----+-----------------+\n",
      "|  vitoria|  2.0|[4.8,3.0,1.4,0.3]|\n",
      "|  vitoria|  2.0|[5.1,3.8,1.6,0.2]|\n",
      "|  vitoria|  2.0|[4.6,3.2,1.4,0.2]|\n",
      "|  vitoria|  2.0|[5.3,3.7,1.5,0.2]|\n",
      "|  vitoria|  2.0|[5.1,3.5,1.4,0.2]|\n",
      "|  vitoria|  2.0|[4.9,3.0,1.4,0.2]|\n",
      "|  vitoria|  2.0|[4.7,3.2,1.3,0.2]|\n",
      "|  vitoria|  2.0|[4.6,3.1,1.5,0.2]|\n",
      "|  vitoria|  2.0|[5.0,3.6,1.4,0.2]|\n",
      "|  vitoria|  2.0|[5.4,3.9,1.7,0.4]|\n",
      "+---------+-----+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select(\"resultado\", \"label\", \"features\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de Treino e de Teste\n",
    "(dados_treino, dados_teste) = df_spark.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_treino.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_teste.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto\n",
    "\n",
    "# quero somente 2 nós de profundidade\n",
    "\n",
    "\n",
    "\n",
    "dtClassifer = DecisionTreeClassifier(maxDepth = 2, labelCol = \"label\", featuresCol = \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina o objeto com dados para criar o modelo\n",
    "modelo = dtClassifer.fit(dados_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hiperparâmetro definido por padrão\n",
    "modelo.numNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hiperparâmetro definido por nós\n",
    "modelo.depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões com dados de teste\n",
    "previsoes = modelo.transform(dados_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[resultado: string, label: double, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=1.0, probability=DenseVector([0.0, 1.0, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='vitoria', label=2.0, prediction=2.0, probability=DenseVector([0.0, 0.0, 1.0])),\n",
       " Row(resultado='vitoria', label=2.0, prediction=2.0, probability=DenseVector([0.0, 0.0, 1.0])),\n",
       " Row(resultado='vitoria', label=2.0, prediction=2.0, probability=DenseVector([0.0, 0.0, 1.0])),\n",
       " Row(resultado='vitoria', label=2.0, prediction=2.0, probability=DenseVector([0.0, 0.0, 1.0])),\n",
       " Row(resultado='vitoria', label=2.0, prediction=2.0, probability=DenseVector([0.0, 0.0, 1.0])),\n",
       " Row(resultado='vitoria', label=2.0, prediction=2.0, probability=DenseVector([0.0, 0.0, 1.0])),\n",
       " Row(resultado='vitoria', label=2.0, prediction=2.0, probability=DenseVector([0.0, 0.0, 1.0])),\n",
       " Row(resultado='vitoria', label=2.0, prediction=2.0, probability=DenseVector([0.0, 0.0, 1.0])),\n",
       " Row(resultado='vitoria', label=2.0, prediction=2.0, probability=DenseVector([0.0, 0.0, 1.0])),\n",
       " Row(resultado='vitoria', label=2.0, prediction=2.0, probability=DenseVector([0.0, 0.0, 1.0])),\n",
       " Row(resultado='vitoria', label=2.0, prediction=2.0, probability=DenseVector([0.0, 0.0, 1.0])),\n",
       " Row(resultado='vitoria', label=2.0, prediction=2.0, probability=DenseVector([0.0, 0.0, 1.0])),\n",
       " Row(resultado='vitoria', label=2.0, prediction=2.0, probability=DenseVector([0.0, 0.0, 1.0])),\n",
       " Row(resultado='vitoria', label=2.0, prediction=2.0, probability=DenseVector([0.0, 0.0, 1.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='derrota', label=0.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='empate', label=1.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='empate', label=1.0, prediction=1.0, probability=DenseVector([0.0, 1.0, 0.0])),\n",
       " Row(resultado='empate', label=1.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='empate', label=1.0, prediction=0.0, probability=DenseVector([0.9286, 0.0714, 0.0])),\n",
       " Row(resultado='empate', label=1.0, prediction=1.0, probability=DenseVector([0.0, 1.0, 0.0])),\n",
       " Row(resultado='empate', label=1.0, prediction=1.0, probability=DenseVector([0.0, 1.0, 0.0])),\n",
       " Row(resultado='empate', label=1.0, prediction=1.0, probability=DenseVector([0.0, 1.0, 0.0])),\n",
       " Row(resultado='empate', label=1.0, prediction=1.0, probability=DenseVector([0.0, 1.0, 0.0])),\n",
       " Row(resultado='empate', label=1.0, prediction=1.0, probability=DenseVector([0.0, 1.0, 0.0])),\n",
       " Row(resultado='empate', label=1.0, prediction=1.0, probability=DenseVector([0.0, 1.0, 0.0])),\n",
       " Row(resultado='empate', label=1.0, prediction=1.0, probability=DenseVector([0.0, 1.0, 0.0])),\n",
       " Row(resultado='empate', label=1.0, prediction=1.0, probability=DenseVector([0.0, 1.0, 0.0])),\n",
       " Row(resultado='empate', label=1.0, prediction=1.0, probability=DenseVector([0.0, 1.0, 0.0]))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformar os resultados para um DF do Pandas para extrair os dados em formato de tabela com cada probabilidade\n",
    "\n",
    "previsoes.select(\"resultado\", \"label\", \"prediction\", \"probability\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando a acurácia\n",
    "avaliador = MulticlassClassificationEvaluator(predictionCol = \"prediction\", \n",
    "                                              labelCol = \"label\", \n",
    "                                              metricName = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9215686274509803"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avaliador.evaluate(previsoes)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       1.0|    1|\n",
      "|  2.0|       2.0|   14|\n",
      "|  0.0|       0.0|   23|\n",
      "|  1.0|       1.0|   10|\n",
      "|  1.0|       0.0|    3|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resumindo as previsões - Confusion Matrix\n",
    "previsoes.groupBy(\"label\", \"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
